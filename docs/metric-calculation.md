# Metric calculation
This section describes how to calculate metrics for the datasets generated by the [OT Platform ETL](https://github.com/opentargets/platform-etl-backend).
## Local setup
  
```bash
git clone https://github.com/opentargets/ot-release-metrics.git
cd ot-release-metrics
python3 -m venv env
source env/bin/activate
python3 -m pip install -r requirements.txt
```

## Submit job to GCP
This will create a Google Cloud instance, SSH into it and install the necessary dependencies. Tweak the commands as necessary.

### Cluster initialization
```bash
export CLUSTER_NAME=ot-release-metrics
export CLUSTER_REGION=europe-west1

gcloud dataproc clusters create ${CLUSTER_NAME} \
    --image-version=2.0 \
    --region=${CLUSTER_REGION} \
    --metadata 'PIP_PACKAGES=pandas==1.3.4 plotly-express==0.4.1 psutil==5.8.0 pyspark==3.2.0 streamlit==1.5.1 click==8 gcsfs==2022.7.1 protobuf==3.20.0 hydra-core==1.2.0' \
    --initialization-actions gs://goog-dataproc-initialization-actions-europe-west1/python/pip-install.sh                                                  \
    --master-machine-type=n1-standard-32 \
    --master-boot-disk-size=100 \
    --max-idle=1h
```

### Job submission
```bash
# Package the repo structure to provision the cluster with it
zip -x src/metric_calculation/metrics.py -r code_bundle.zip .

gcloud dataproc jobs submit pyspark \
  src/metric_calculation/metrics.py \
  --cluster=${CLUSTER_NAME} \
  --py-files code_bundle.zip \
  --files='config/config.yaml'
```
