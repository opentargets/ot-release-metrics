# Metric calculation
This section describes how to calculate metrics for the datasets generated by the [OT Platform ETL](https://github.com/opentargets/platform-etl-backend).

## Configure the run
If you are running in pre-ETL mode, set:
```bash
# Substitute the upcoming release, for example 23.12.
RUN_ID="XX.YY-pre"
ETL_RUN_ID="null"
IS_PRE_ETL_RUN="true"
```

If you are running in post-ETL mode, set:
```bash
# Substitute XX.YY with the upcoming release, and YYYYMMDD with the timestamp for the date on which the ETL was run. This is essential to be able to compare multiple ETL runs throughout the release preparation process.
RUN_ID="XX.YY.YYYYMMDD"
# Substite XX.YY with the upcoming release. Consequent ETL runs are stored in the same bucket, overwriting its contents, so this path is the same for all ETL runs for the release.
ETL_RUN_ID="XX.YY"
IS_PRE_ETL_RUN="false"
```

## Submit job to Dataproc
```bash
export IMAGE=gcr.io/open-targets-eu-dev/ot-release-metrics:latest
export REGION=europe-west1
export BUCKET=gs://ot-release-metrics
gcloud dataproc batches submit pyspark \
    --container-image ${IMAGE} \
    --region ${REGION} \
    --deps-bucket ${BUCKET} \
    --files config/config.yaml \
    --properties "spark.executor.cores=16" \
    src/metric_calculation/metrics.py \
    -- \
    metric_calculation.run_id=${RUN_ID} \
    metric_calculation.etl_run_id=${ETL_RUN_ID} \
    metric_calculation.is_pre_etl_run=${IS_PRE_ETL_RUN}
```

## Update the Streamlit app
If the Streamlit app was already deployed at the time when the above code was run, it will not be able to automatically pick up the new metrics. Reboot it manually to reflect the new changes. See instructions in the [app documentation](metric-visualisation.md#rebooting-the-app).
