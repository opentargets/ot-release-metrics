# Metric calculation
This section describes how to calculate metrics for the datasets generated by the [OT Platform ETL](https://github.com/opentargets/platform-etl-backend).
## Local setup
  
```bash
git clone https://github.com/opentargets/ot-release-metrics.git
cd ot-release-metrics
python3 -m venv env
source env/bin/activate
python3 -m pip install -r requirements.txt
```

## Submit job to GCP
This will create a Google Cloud instance, SSH into it and install the necessary dependencies. Tweak the commands as necessary.

### Cluster initialization
```bash
export CLUSTER_NAME=ot-release-metrics
export CLUSTER_REGION=europe-west1

gcloud dataproc clusters create ${CLUSTER_NAME} \
    --image-version=2.1 \
    --single-node \
    --region=${CLUSTER_REGION} \
    --metadata 'PIP_PACKAGES=hydra-core==1.2.0 gcsfs==2022.7.1' \
    --initialization-actions gs://goog-dataproc-initialization-actions-europe-west1/python/pip-install.sh                                                  \
    --master-machine-type=n1-standard-64 \
    --master-boot-disk-size=100 \
    --max-idle=10m \
    --project open-targets-eu-dev
```

### Job submission
```bash
# Package the repo structure to provision the cluster with it
zip -r code_bundle.zip . -x "src/metric_calculation/metrics.py" "env/*" "src/assets/*" ".git/*" "outputs/*" "docs/*"

gcloud dataproc jobs submit pyspark \
  src/metric_calculation/metrics.py \
  --cluster=${CLUSTER_NAME} \
  --region=${CLUSTER_REGION} \
  --py-files code_bundle.zip \
  --files='config/config.yaml' \
  --project open-targets-eu-dev
```

### Updating the Streamlit app
If the Streamlit app was already deployed at the time when the above code was run, you'll need to reboot it to reflect the new changes. See instructions in the [app documentation](metric-visualisation.md#rebooting-the-app).
